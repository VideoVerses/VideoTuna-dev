flow:
  target: videotuna.flow.wanvideo.WanVideoModelFlow
  params:
    task: "t2v-14B"                   
    ckpt_path: "checkpoints/wan/Wan2.1-T2V-14B"                    
    offload_model: true               
    ulysses_size: 1          
    ring_size: 1                      
    t5_fsdp: false                   
    t5_cpu: false                     
    dit_fsdp: false                   
    use_prompt_extend: false          
    prompt_extend_method: "local_qwen"
    prompt_extend_model: null         
    prompt_extend_target_lang: "zh"  
    seed: 42       

    denoiser_config:
      target: videotuna.models.wan.wan.modules.model.WanModel
      use_from_pretrained: true
      params:
        pretrained_model_name_or_path: ${flow.params.ckpt_path}

    first_stage_config:
      target: videotuna.models.wan.wan.modules.vae.WanVAE_
      params:
        dim: 96
        z_dim: 16
        dim_mult: [1, 2, 4, 4]
        num_res_blocks: 2
        attn_scales: []
        temperal_downsample: [false, true, true]
        dropout: 0.0

    cond_stage_config:
      target: videotuna.models.wan.wan.modules.t5.T5Encoder
      params:
        dim: 4096
        dim_attn: 4096
        dim_ffn: 10240
        num_heads: 64
        num_buckets: 32
        shared_pos: false
        dropout: 0.1
        vocab: 256384
        num_layers: 24

train:
  ckpt: checkpoints/wan/Wan2.1-T2V-14B
  name: train_wan_t2v_fullft
  logdir: results/train
  seed: 42
  debug: false         
  first_stage_key: video
  cond_stage_key: caption
  mapping:
    train.ckpt : flow.params.ckpt_path

  lr_config:
    base_learning_rate: 6.0e-06
    scale_lr: False

  data:
    target: videotuna.data.lightningdata.DataModuleFromConfig
    params:
      batch_size: 1
      num_workers: 16
      wrap: false
      train:
        target: videotuna.data.datasets.DatasetFromCSV
        params:
          csv_path: data/apply_lipstick/metadata.csv
          height: 480
          width: 832
          num_frames: 81
          frame_interval: 1
          train: True

  lightning:
    strategy: deepspeed_stage_3_offload
    trainer:
      accelerator: gpu
      benchmark: True
      num_nodes: 1
      accumulate_grad_batches: 1
      max_epochs: 2000
      precision: bf16-mixed
    callbacks:
      image_logger:
        target: videotuna.utils.callbacks.ImageLogger
        params:
          batch_frequency: 50
          max_images: 6
          to_local: True # save videos into files
          log_images_kwargs:
            unconditional_guidance_scale: 12.0 # need this, otherwise it is grey
      model_checkpoint:
        target: videotuna.utils.callbacks.VideoTunaModelCheckpoint
        params:
          filename: "{epoch:03}-{step:09}"
          save_only_selected_model: True
          selected_model: ["denoiser"]
          save_weights_only: False
          save_on_train_epoch_end: False
          save_last: True
          every_n_epochs: 0
          every_n_train_steps: 50

inference:
  mode: t2v
  ckpt_path: "checkpoints/wan/Wan2.1-T2V-14B"
  savedir: results/t2v/wanvideo
  seed: 42
  height: 480
  width: 832
  image: null                       
  prompt_file: 'Two anthropomorphic cats in comfy boxing gear and bright gloves fight intensely on a spotlighted stage.'                     
  solver: "unipc"           
  num_inference_steps: 50                
  time_shift: 3.0                
  unconditional_guidance_scale: 5.0                        
  frames: 81
  n_samples_prompt: 1
  bs: 1
  savefps: 30
  enable_model_cpu_offload: true

  mapping:
    inference.ckpt_path : flow.params.ckpt_path
    inference.seed : flow.params.seed
    inference.enable_model_cpu_offload : flow.params.offload_model
    